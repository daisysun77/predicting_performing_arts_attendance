{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cf7009",
   "metadata": {},
   "source": [
    "# Predicting Performing Arts Attendance with Machine Learning\n",
    "\n",
    "## - ML Trained and Tuned with Five Seeds\n",
    "\n",
    "August 8, 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_curve \n",
    "from sklearn.metrics import auc, roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "import shap\n",
    "shap.initjs()  # load JS for visualization in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f62fed",
   "metadata": {},
   "source": [
    "## Load & clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'code_01_data_cleaning.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35242fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a29850",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vars = ['ATTEND']\n",
    "df_Y = df[y_vars]\n",
    "df_X = df.drop(columns=y_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5457db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7faf0",
   "metadata": {},
   "source": [
    "## Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "\n",
    "def md5_hash(input_string):\n",
    "    \"\"\"Generates an MD5 hash from a given string.\n",
    "    Args:\n",
    "    input_string: The string to hash.\n",
    "    Returns:\n",
    "    The MD5 hash as a hexadecimal string.\n",
    "    \"\"\"\n",
    "    md5_hasher = hashlib.md5()\n",
    "    md5_hasher.update(input_string.encode('utf-8'))\n",
    "    return md5_hasher.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ca08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"performingartsattendance\"\n",
    "hashed_value = md5_hash(input_string)\n",
    "print(f\"The MD5 hash of '{input_string}' is: {hashed_value}\")\n",
    "\n",
    "# Convert the hexadecimal hash to an integer\n",
    "try:\n",
    "    number = int(hashed_value, 16)\n",
    "    print(f\"The integer representation of the hash is: {number}\")\n",
    "except ValueError:\n",
    "    print(\"Invalid hexadecimal string\")\n",
    "\n",
    "# Set the seed value\n",
    "random.seed(number)\n",
    "\n",
    "print(f\"Initial seed number: {number}\")\n",
    "\n",
    "# Generate a list of random numbers\n",
    "n_seeds = 5\n",
    "random.seed(number)\n",
    "a = 0\n",
    "b = 2**31-1\n",
    "seeds = [random.randint(a, b) for _ in range(n_seeds)]\n",
    "\n",
    "# Print the list\n",
    "print(\"Seed\", seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79870888",
   "metadata": {},
   "source": [
    "## Set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_split(seed, df_X, df_y, test_size=0.2):\n",
    "    return train_test_split(df_X, df_y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d803f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['REGION', 'STATEFIP', 'METRO', \n",
    "                    'SEX', 'RACE', 'HISPAN', 'VETSTAT', 'YRIMMIG', 'MARST',\n",
    "                    'EMPSTAT', 'CLASSWKR',\n",
    "                    'EDUC99',\n",
    "                    'SCHLCOLL', 'PROFCERT',\n",
    "                    'DIFFHEAR', 'DIFFEYE', 'DIFFREM',\n",
    "                    'DIFFPHYS', 'DIFFMOB', 'DIFFANY']\n",
    "numerical_vars = [col for col in df_X.columns if col not in categorical_vars]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, categorical_vars),\n",
    "    ('num', num_pipeline, numerical_vars)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb957c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf: trained\n",
    "def evaluate_model(seed, clf, X_test_transformed, y_test):\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test_transformed)\n",
    "    y_prob = clf.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_prob),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'roc_curve': roc_curve(y_test, y_prob),\n",
    "        'report': classification_report(y_test, y_pred),\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'clf': clf\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f8ea2",
   "metadata": {},
   "source": [
    "## CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a8153",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e653e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci(x):\n",
    "    x = x.dropna()\n",
    "    n = len(x)\n",
    "    mean = x.mean()\n",
    "    median = x.median()\n",
    "    sd = x.std(ddof=1)\n",
    "    se = sd / np.sqrt(n)\n",
    "    ci = stats.t.interval(0.95, df=n-1, loc=mean, scale=se) if n > 1 else (np.nan, np.nan)\n",
    "    return pd.Series({\n",
    "        'mean': mean,\n",
    "        'median': median,\n",
    "        'n': n,\n",
    "        'ci_lower': ci[0],\n",
    "        'ci_upper': ci[1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd6e18",
   "metadata": {},
   "source": [
    "<p style=\"padding: 15px; background-color: skyblue; color: black; font-weight: bold;\n",
    "          text-align: center; font-size: 170%\">Machine Learning</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = 'ATTEND'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941d448",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RF'\n",
    "model_fullname = 'Random Forest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9318db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf_default(seed, df_X, df_y, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Classifier\n",
    "    clf = RandomForestClassifier(random_state=seed)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.extend([{\n",
    "    'y': ycol,\n",
    "    'model': model_name,\n",
    "    'cv': 0,\n",
    "    **model_rf_default(s, df_X, df_Y[ycol])}\n",
    "    for s in seeds\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(trial, seed, cv, X_train_transformed, y_train):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 64, log=True),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 50),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None, 0.2, 0.5, 0.8]),\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    clf = RandomForestClassifier(**params, random_state=seed)\n",
    "    \n",
    "    # Cross-validated F1 score\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=seed)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_transformed, y_train):\n",
    "        X_train_cv, X_val_cv = X_train_transformed[train_idx], X_train_transformed[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Compute sample weights for the training fold\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_cv)\n",
    "\n",
    "        # Fit with sample weights\n",
    "        clf.fit(X_train_cv, y_train_cv, sample_weight=sample_weights)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = clf.predict(X_val_cv)\n",
    "        f1 = f1_score(y_val_cv, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5017ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf_tuned(seed, cv, df_X, df_y, n_trials=n_trials, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "\n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Tune model\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: rf_objective(trial, seed, cv, X_train_transformed, y_train), \n",
    "                   n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # Use best parameters to train final model\n",
    "    clf = RandomForestClassifier(**best_params, random_state=seed)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3149e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in cvs:\n",
    "    results.extend([{\n",
    "        'y': ycol,\n",
    "        'model': model_name,\n",
    "        'cv': cv,\n",
    "        **model_rf_tuned(s, cv, df_X, df_Y[ycol])}\n",
    "        for s in seeds\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64aec14",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65154b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "plotdf = results_df[results_df['model'] == model_name].copy()\n",
    "plotdf.drop(columns=['y_test', 'y_pred', 'y_prob', 'roc_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'RF'].groupby('cv')['f1'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='f1').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df199393",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'RF'].groupby('cv')['auc'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='auc').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'RF'].groupby('cv')['accuracy'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='accuracy').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'RF'].groupby('cv')['precision'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='precision').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'RF'].groupby('cv')['recall'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='recall').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04175587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping from unique cv values to readable labels\n",
    "plotdf['cv_label'] = plotdf['cv'].apply(lambda x: 'Default' if x == 0 else f'Tuned cv={int(x)}')\n",
    "\n",
    "# Create the boxplot\n",
    "PROPS = {\n",
    "    'boxprops':{'facecolor':'white', 'edgecolor':'black'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'black'}\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "sns.boxplot(x='cv_label', y='f1', data=plotdf, linewidth=1, ax=axs[0], **PROPS)\n",
    "axs[0].set_ylabel('F1 Score')\n",
    "sns.boxplot(x='cv_label', y='auc', data=plotdf, linewidth=1, ax=axs[1], **PROPS)\n",
    "axs[1].set_ylabel('AUC')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Model Type\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, axis='y')\n",
    "    \n",
    "plt.suptitle(f\"{ycol} - {model_fullname}: Evaluation metrics with {n_seeds} seeds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50cf5de",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c82aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'GB'\n",
    "model_fullname = 'Gradient Boosting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960444af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gb_default(seed, df_X, df_y, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Classifier\n",
    "    clf = GradientBoostingClassifier(random_state=seed)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.extend([{\n",
    "    'y': ycol,\n",
    "    'model': model_name,\n",
    "    'cv': 0,\n",
    "    **model_gb_default(s, df_X, df_Y[ycol])}\n",
    "    for s in seeds\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfa29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_objective(trial, seed, cv, X_train_transformed, y_train):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 50),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0, step=0.05),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None, 0.2, 0.5, 0.8])\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    clf = GradientBoostingClassifier(**params, random_state=seed)\n",
    "    \n",
    "    # Cross-validated F1 score\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=seed)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_transformed, y_train):\n",
    "        X_train_cv, X_val_cv = X_train_transformed[train_idx], X_train_transformed[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Compute sample weights for the training fold\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_cv)\n",
    "\n",
    "        # Fit with sample weights\n",
    "        clf.fit(X_train_cv, y_train_cv, sample_weight=sample_weights)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = clf.predict(X_val_cv)\n",
    "        f1 = f1_score(y_val_cv, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gb_tuned(seed, cv, df_X, df_y, n_trials=n_trials, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "\n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Tune model\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: gb_objective(trial, seed, cv, X_train_transformed, y_train), \n",
    "                   n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # Use best parameters to train final model\n",
    "    clf = GradientBoostingClassifier(**best_params, random_state=seed)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in cvs:\n",
    "    results.extend([{\n",
    "        'y': ycol,\n",
    "        'model': model_name,\n",
    "        'cv': cv,\n",
    "        **model_gb_tuned(s, cv, df_X, df_Y[ycol])}\n",
    "        for s in seeds\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff2433",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "plotdf = results_df[results_df['model'] == model_name].copy()\n",
    "plotdf.drop(columns=['y_test', 'y_pred', 'y_prob', 'roc_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'GB'].groupby('cv')['f1'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='f1').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'GB'].groupby('cv')['auc'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='auc').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ffe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'GB'].groupby('cv')['accuracy'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='accuracy').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f285d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'GB'].groupby('cv')['precision'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='precision').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'GB'].groupby('cv')['recall'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='recall').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping from unique cv values to readable labels\n",
    "plotdf['cv_label'] = plotdf['cv'].apply(lambda x: 'Default' if x == 0 else f'Tuned cv={int(x)}')\n",
    "\n",
    "# Create the boxplot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "sns.boxplot(x='cv_label', y='f1', data=plotdf, linewidth=1, ax=axs[0], **PROPS)\n",
    "axs[0].set_ylabel('F1 Score')\n",
    "sns.boxplot(x='cv_label', y='auc', data=plotdf, linewidth=1, ax=axs[1], **PROPS)\n",
    "axs[1].set_ylabel('AUC')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Model Type\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, axis='y')\n",
    "    \n",
    "plt.suptitle(f\"{ycol} - {model_fullname}: Evaluation metrics with {n_seeds} seeds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db78e18",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB'\n",
    "model_fullname = 'XGBoost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52172e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgb_default(seed, df_X, df_y, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Classifier\n",
    "    clf = XGBClassifier(random_state=seed)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e62973",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.extend([{\n",
    "    'y': ycol,\n",
    "    'model': model_name,\n",
    "    'cv': 0,\n",
    "    **model_xgb_default(s, df_X, df_Y[ycol])}\n",
    "    for s in seeds\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial, seed, cv, X_train_transformed, y_train):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 100.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 100.0, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 100),\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    clf = XGBClassifier(**params, random_state=seed)\n",
    "    \n",
    "    # Cross-validated F1 score\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=seed)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_transformed, y_train):\n",
    "        X_train_cv, X_val_cv = X_train_transformed[train_idx], X_train_transformed[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Compute sample weights for the training fold\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_cv)\n",
    "\n",
    "        # Fit with sample weights\n",
    "        clf.fit(X_train_cv, y_train_cv, sample_weight=sample_weights)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = clf.predict(X_val_cv)\n",
    "        f1 = f1_score(y_val_cv, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgb_tuned(seed, cv, df_X, df_y, n_trials=n_trials, preprocessor=preprocessor):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = set_split(seed, df_X, df_y)\n",
    "\n",
    "    # Preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Tune model\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: xgb_objective(trial, seed, cv, X_train_transformed, y_train), \n",
    "                   n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # Use best parameters to train final model\n",
    "    clf = XGBClassifier(**best_params, random_state=seed)\n",
    "\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    clf.fit(X_train_transformed, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_model(seed, clf, X_test_transformed, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in cvs:\n",
    "    results.extend([{\n",
    "        'y': ycol,\n",
    "        'model': model_name,\n",
    "        'cv': cv,\n",
    "        **model_xgb_tuned(s, cv, df_X, df_Y[ycol])}\n",
    "        for s in seeds\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa8e86",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "plotdf = results_df[results_df['model'] == model_name].copy()\n",
    "plotdf.drop(columns=['y_test', 'y_pred', 'y_prob', 'roc_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'XGB'].groupby('cv')['f1'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='f1').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'XGB'].groupby('cv')['auc'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='auc').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'XGB'].groupby('cv')['accuracy'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='accuracy').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'XGB'].groupby('cv')['precision'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='precision').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'XGB'].groupby('cv')['recall'].apply(compute_ci).reset_index().pivot(\n",
    "    index='cv', columns='level_1', values='recall').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping from unique cv values to readable labels\n",
    "plotdf['cv_label'] = plotdf['cv'].apply(lambda x: 'Default' if x == 0 else f'Tuned cv={int(x)}')\n",
    "\n",
    "# Create the boxplot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "sns.boxplot(x='cv_label', y='f1', data=plotdf, linewidth=1, ax=axs[0], **PROPS)\n",
    "axs[0].set_ylabel('F1 Score')\n",
    "sns.boxplot(x='cv_label', y='auc', data=plotdf, linewidth=1, ax=axs[1], **PROPS)\n",
    "axs[1].set_ylabel('AUC')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Model Type\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, axis='y')\n",
    "    \n",
    "plt.suptitle(f\"{ycol} - {model_fullname}: Evaluation metrics with {n_seeds} seeds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484dc1a6",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebe29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new label that combines model and CV setting\n",
    "df['model_cv'] = df['model'] + \" | cv=\" + df['cv'].astype(str)\n",
    "\n",
    "# Define your preferred model order\n",
    "model_order = ['RF', 'GB', 'XGB']\n",
    "cv_order = sorted(df['cv'].unique(), key=lambda x: int(x))\n",
    "ordered_model_cv = [f\"{model} | cv={cv}\" for model in model_order for cv in cv_order]\n",
    "\n",
    "# Plot boxplot of F1 scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='model_cv', y='f1', data=df, linewidth=1, **PROPS, order=ordered_model_cv)\n",
    "\n",
    "plt.xlabel(\"Model and CV Setting\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(f\"{ycol} - F1 Score by Model Type\")\n",
    "plt.xticks(rotation=0, ha='center')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot of AUC\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='model_cv', y='auc', data=df, linewidth=1, **PROPS, order=ordered_model_cv)\n",
    "\n",
    "plt.xlabel(\"Model and CV Setting\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(f\"{ycol} - AUC by Model Type\")\n",
    "plt.xticks(rotation=0, ha='center')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6ddcb",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mdl in results:\n",
    "#     joblib.dump(mdl['clf'], f\"models/{mdl['y']}_{mdl['model']}_cv{mdl['cv']:.0f}_seed{mdl['seed']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bca489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
