{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cf7009",
   "metadata": {},
   "source": [
    "# Predicting Performing Arts Attendance with Machine Learning\n",
    "\n",
    "## - SHAP Analysis\n",
    "\n",
    "August 8, 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_curve \n",
    "from sklearn.metrics import auc, roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import shap\n",
    "shap.initjs()  # load JS for visualization in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f62fed",
   "metadata": {},
   "source": [
    "## Load & clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'code_01_data_cleaning.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35242fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a29850",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vars = ['ATTEND']\n",
    "df_Y = df[y_vars]\n",
    "df_X = df.drop(columns=y_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5457db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7faf0",
   "metadata": {},
   "source": [
    "## Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "\n",
    "def md5_hash(input_string):\n",
    "    \"\"\"Generates an MD5 hash from a given string.\n",
    "    Args:\n",
    "    input_string: The string to hash.\n",
    "    Returns:\n",
    "    The MD5 hash as a hexadecimal string.\n",
    "    \"\"\"\n",
    "    md5_hasher = hashlib.md5()\n",
    "    md5_hasher.update(input_string.encode('utf-8'))\n",
    "    return md5_hasher.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ca08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"performingartsattendance\"\n",
    "hashed_value = md5_hash(input_string)\n",
    "print(f\"The MD5 hash of '{input_string}' is: {hashed_value}\")\n",
    "\n",
    "# Convert the hexadecimal hash to an integer\n",
    "try:\n",
    "    number = int(hashed_value, 16)\n",
    "    print(f\"The integer representation of the hash is: {number}\")\n",
    "except ValueError:\n",
    "    print(\"Invalid hexadecimal string\")\n",
    "\n",
    "# Set the seed value\n",
    "random.seed(number)\n",
    "\n",
    "print(f\"Initial seed number: {number}\")\n",
    "\n",
    "# Generate a list of random numbers\n",
    "n_seeds = 5\n",
    "random.seed(number)\n",
    "a = 0\n",
    "b = 2**31-1\n",
    "seeds = [random.randint(a, b) for _ in range(n_seeds)]\n",
    "\n",
    "# Print the list\n",
    "print(\"Seed\", seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79870888",
   "metadata": {},
   "source": [
    "## Set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_split(seed, df_X, df_y, test_size=0.2):\n",
    "    return train_test_split(df_X, df_y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d803f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['REGION', 'STATEFIP', 'METRO', \n",
    "                    'SEX', 'RACE', 'HISPAN', 'VETSTAT', 'YRIMMIG', 'MARST',\n",
    "                    'EMPSTAT', 'CLASSWKR',\n",
    "                    'EDUC99',\n",
    "                    'SCHLCOLL', 'PROFCERT',\n",
    "                    'DIFFHEAR', 'DIFFEYE', 'DIFFREM',\n",
    "                    'DIFFPHYS', 'DIFFMOB', 'DIFFANY']\n",
    "numerical_vars = [col for col in df_X.columns if col not in categorical_vars]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, categorical_vars),\n",
    "    ('num', num_pipeline, numerical_vars)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb957c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf: trained\n",
    "def evaluate_model(seed, clf, X_test_transformed, y_test):\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test_transformed)\n",
    "    y_prob = clf.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_prob),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'roc_curve': roc_curve(y_test, y_prob),\n",
    "        'report': classification_report(y_test, y_pred),\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'clf': clf\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6ddcb",
   "metadata": {},
   "source": [
    "## GB SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa70459",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = 'ATTEND'\n",
    "bestmodel = 'GB'\n",
    "bestcv = '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714db733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect SHAP Explanation objects from each seed\n",
    "shap_values_array = []\n",
    "base_value_array = []\n",
    "X_transformed_display_list = []\n",
    "\n",
    "# Fit the preprocessor once\n",
    "preprocessor.fit(df_X)\n",
    "\n",
    "# Utility to extract transformed feature names\n",
    "def get_feature_names(preprocessor):\n",
    "    feature_names = []\n",
    "    for name, transformer, cols in preprocessor.transformers_:\n",
    "        if transformer == 'drop':\n",
    "            continue\n",
    "        elif transformer == 'passthrough':\n",
    "            feature_names.extend(cols)\n",
    "        elif hasattr(transformer, 'get_feature_names_out'):\n",
    "            names = transformer.get_feature_names_out(cols)\n",
    "            feature_names.extend(names)\n",
    "        else:\n",
    "            raise ValueError(f\"Unhandled transformer type: {name}\")\n",
    "    return feature_names\n",
    "\n",
    "transformed_feature_names = get_feature_names(preprocessor)\n",
    "\n",
    "\n",
    "for seed in seeds[:2]:\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y['ATTEND'], test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Transform using preprocessor\n",
    "    X_train_transformed = preprocessor.transform(X_train).toarray()\n",
    "    X_test_transformed = preprocessor.transform(X_test).toarray()\n",
    "\n",
    "    # Fit final model\n",
    "    final_model = joblib.load(f\"models/{ycol}_{bestmodel}_cv{bestcv}_seed{seed}.pkl\")\n",
    "    final_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # SHAP explanation\n",
    "    X_sample = X_test_transformed[:1000]\n",
    "    explainer = shap.TreeExplainer(final_model)\n",
    "    shap_values = explainer(X_sample)\n",
    "    \n",
    "    # Collect\n",
    "    shap_values_array.append(shap_values.values)\n",
    "    base_value_array.append(shap_values.base_values)\n",
    "    \n",
    "    X_df_sample = pd.DataFrame(X_sample, columns=transformed_feature_names).astype(float)\n",
    "    X_transformed_display_list.append(X_df_sample)\n",
    "    \n",
    "# Combine results\n",
    "shap_values_concat = np.vstack(shap_values_array)               # shape (n_total, n_features)\n",
    "base_values_concat = np.hstack(base_value_array)               # shape (n_total,)\n",
    "X_display_concat = pd.concat(X_transformed_display_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize (first 100 for force plot)\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_values_concat[:1000],\n",
    "    shap_values_concat[:1000],\n",
    "    X_display_concat.iloc[:1000],\n",
    "    feature_names=transformed_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values_concat,\n",
    "    X_display_concat,\n",
    "    feature_names=transformed_feature_names,\n",
    "#     max_display=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean absolute SHAP value for each feature\n",
    "mean_abs_shap = np.abs(shap_values_concat).mean(axis=0)\n",
    "\n",
    "# Build DataFrame\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    'Feature': transformed_feature_names,\n",
    "    'MeanAbsSHAP': mean_abs_shap\n",
    "}).sort_values(by='MeanAbsSHAP', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 20\n",
    "shap_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group OneHot columns\n",
    "shap_df = pd.DataFrame(\n",
    "    shap_values_concat,\n",
    "    columns=transformed_feature_names\n",
    ")\n",
    "\n",
    "grouped_shap_df = pd.DataFrame()\n",
    "for var in categorical_vars:\n",
    "    cols = [c for c in shap_df.columns if c.startswith(var + '_')]\n",
    "    if cols:\n",
    "        grouped_shap_df[var] = shap_df[cols].abs().sum(axis=1)\n",
    "for var in numerical_vars:\n",
    "    grouped_shap_df[var] = shap_df[var].abs()\n",
    "\n",
    "\n",
    "mean_abs_importance = grouped_shap_df.mean().sort_values(ascending=False)\n",
    "mean_abs_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fff34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3326a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual instance\n",
    "i = 0\n",
    "\n",
    "shap.force_plot(\n",
    "    base_values_concat[i],\n",
    "    shap_values_concat[i],\n",
    "    X_display_concat.iloc[i],\n",
    "    feature_names=transformed_feature_names,\n",
    "    matplotlib=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Explanation object if needed\n",
    "single_explanation = shap.Explanation(\n",
    "    values=shap_values_concat[i],\n",
    "    base_values=base_values_concat[i],\n",
    "    data=X_display_concat.iloc[i].values,\n",
    "    feature_names=transformed_feature_names\n",
    ")\n",
    "\n",
    "# Waterfall plot\n",
    "shap.plots.waterfall(single_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61352d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "\n",
    "shap.force_plot(\n",
    "    base_values_concat[i],\n",
    "    shap_values_concat[i],\n",
    "    X_display_concat.iloc[i],\n",
    "    feature_names=transformed_feature_names,\n",
    "    matplotlib=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Explanation object if needed\n",
    "single_explanation = shap.Explanation(\n",
    "    values=shap_values_concat[i],\n",
    "    base_values=base_values_concat[i],\n",
    "    data=X_display_concat.iloc[i].values,\n",
    "    feature_names=transformed_feature_names\n",
    ")\n",
    "\n",
    "# Waterfall plot\n",
    "shap.plots.waterfall(single_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd980955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
